\documentclass[12pt,a4paper]{article}

% Package to include code
\usepackage{listings}
\usepackage{color}
\lstset{language=Python}
\lstset{numbers=none, basicstyle=\footnotesize\ttfamily,
  numberstyle=\tiny,keywordstyle=\color{blue},stringstyle=\ttfamily,showstringspaces=false}
\lstset{backgroundcolor=\color[rgb]{0.95 0.95 0.95}}
\lstdefinestyle{numbers}{numbers=left, stepnumber=1, numberstyle=\tiny, numbersep=10pt,basicstyle=\footnotesize\ttfamily}
\lstdefinestyle{nonumbers}{numbers=none,basicstyle=\footnotesize\ttfamily}
\lstdefinestyle{tiny}{numbers=none,basicstyle=\tiny\ttfamily}

% Font selection: uncomment the next line to use the ``beton'' font
%\usepackage{beton}

% Font selection: uncomment the next line to use the ``times'' font
%\usepackage{times}

% Font for equations
\usepackage{euler}


%Package to define the headers and footers of the pages
\usepackage{fancyhdr}


%Package to include an index
\usepackage{index}

%Package to display boxes around texts. Used especially for the internal notes.
\usepackage{framed}

%PSTricks is a collection of PostScript-based TEX macros that is compatible
% with most TEX macro packages
\usepackage{pstricks}
\usepackage{pst-node}
\usepackage{pst-plot}
\usepackage{pst-tree}

%Package to display boxes around a minipage. Used especially to
%describe the biography of people.
\usepackage{boxedminipage}

%Package to include postscript figures
\usepackage{epsfig}

%Package for the bibliography
% \cite{XXX} produces Ben-Akiva et. al., 2010
% \citeasnoun{XXX} produces Ben-Akiva et al. (2010)
% \citeasnoun*{XXX} produces Ben-Akiva, Bierlaire, Bolduc and Walker (2010)
\usepackage[dcucite,abbr]{harvard}
\harvardparenthesis{none}\harvardyearparenthesis{round}

%Packages for advanced mathematics typesetting
\usepackage{amsmath,amsfonts,amssymb}

%Package to display trees easily
%\usepackage{xyling}

%Package to include smart references (on the next page, on the
%previous page, etc.) 
%%

%% Remove as it is not working when the book will be procesed by the
%% publisher.
%\usepackage{varioref}

%Package to display the euro sign
\usepackage[right,official]{eurosym}

%Rotate material, especially large table (defines sidewaystable)
\usepackage[figuresright]{rotating}

%Defines the subfigure environment, to obtain refs like Figure 1(a)
%and Figure 1(b). 
\usepackage{subfigure}

%Package for appendices. Allows subappendices, in particular
\usepackage{appendix}

%Package controling the fonts for the captions
\usepackage[font={small,sf}]{caption}

%Defines new types of columns for tabular ewnvironment
\usepackage{dcolumn}
\newcolumntype{d}{D{.}{.}{-1}}
\newcolumntype{P}[1]{>{#1\hspace{0pt}\arraybackslash}}
\newcolumntype{.}{D{.}{.}{9.3}}

%Allows multi-row cells in tables
\usepackage{multirow}

%Tables spaning more than one page
\usepackage{longtable}


%%
%%  Macros by Michel
%%

%Internal notes
\newcommand{\note}[1]{
\begin{framed}{}%
\textbf{\underline{Internal note}:} #1
\end{framed}}

%Use this version to turn off the notes
%\newcommand{\note}[1]{}


%Include a postscript figure . Note that the label is prefixed with
%``fig:''. Remember it when you refer to it.  
%Three arguments:
% #1 label
% #2 file (without extension)
% #3 Caption
\newcommand{\afigure}[3]{%
\begin{figure}[!tbp]%
\begin{center}%
\epsfig{figure=#2,width=0.8\textwidth}%
\end{center}
\caption{\label{fig:#1} #3}%
\end{figure}}






%Include two postscript figures side by side. 
% #1 label of the first figure
% #2 file for the first figure
% #3 Caption for the first figure
% #4 label of the second figure
% #5 file for the second figure
% #6 Caption for the first figure
% #7 Caption for the set of two figures
\newcommand{\twofigures}[7]{%
\begin{figure}[htb]%
\begin{center}%
\subfigure[\label{fig:#1}#3]{\epsfig{figure=#2,width=0.45\textwidth}}%
\hfill
\subfigure[\label{fig:#4}#6]{\epsfig{figure=#5,width=0.45\textwidth}}%
\end{center}
\caption{#7}%
\end{figure}}

%Include a figure generated by gnuplot using the epslatex output. Note that the label is prefixed with
%``fig:''. Remember it when you refer to it.  
 
%Three arguments:
% #1 label
% #2 file (without extension)
% #3 Caption
\newcommand{\agnuplotfigure}[3]{%
\begin{figure}[!tbp]%
\begin{center}%
\input{#2}%
\end{center}
\caption{\label{fig:#1} #3}%
\end{figure}}

%Three arguments:
% #1 label
% #2 file (without extension)
% #3 Caption
\newcommand{\asidewaysgnuplotfigure}[3]{%
\begin{sidewaysfigure}[!tbp]%
\begin{center}%
\input{#2}%
\end{center}
\caption{\label{fig:#1} #3}%
\end{sidewaysfigure}}


%Include two postscript figures side by side. 
% #1 label of the first figure
% #2 file for the first figure
% #3 Caption for the first figure
% #4 label of the second figure
% #5 file for the second figure
% #6 Caption for the second figure
% #7 Caption for the set of two figures
% #8 label for the whole figure
\newcommand{\twognuplotfigures}[7]{%
\begin{figure}[htb]%
\begin{center}%
\subfigure[\label{fig:#1}#3]{\input{#2}}%
\hfill
\subfigure[\label{fig:#4}#6]{\input{#5}}%
\end{center}
\caption{#7}%
\end{figure}}



%Include the description of somebody. Four arguments:
% #1 label
% #2 Name
% #3 file (without extension)
% #4 description
\newcommand{\people}[4]{
\begin{figure}[tbf]
\begin{boxedminipage}{\textwidth}
\parbox{0.40\textwidth}{\epsfig{figure=#3,width = 0.39\textwidth}}%\hfill
\parbox{0.59\textwidth}{%
#4% 
}%
\end{boxedminipage}
\caption{\label{fig:#1} #2}
\end{figure}
}

%Default command for a definition
% #1 label (prefix def:)
% #2 concept to be defined
% #3 definition
\newtheorem{definition}{Definition}
\newcommand{\mydef}[3]{%
\begin{definition}%
\index{#2|textbf}%
\label{def:#1}%
\textbf{#2} \slshape #3\end{definition}}

%Reference to a definitoin. Prefix 'def:' is assumed
\newcommand{\refdef}[1]{definition~\ref{def:#1}}


%Default command for a theorem, with proof
% #1: label (prefix thm:)
% #2: name of the theorem
% #3: statement
% #4: proof
\newtheorem{theorem}{Theorem}
\newcommand{\mytheorem}[4]{%
\begin{theorem}%
\index{#2|textbf}%
\index{Theorems!#2}%
\label{thm:#1}%
\textbf{#2} \sffamily \slshape #3
\end{theorem} \bpr #4 \epr \par}


%Default command for a theorem, without proof
% #1: label (prefix thm:)
% #2: name of the theorem
% #3: statement
\newcommand{\mytheoremsp}[3]{%
\begin{theorem}%
\index{#2|textbf}%
\index{Theorems!#2}%
\label{thm:#1}%
\textbf{#2} \sffamily \slshape #3
\end{theorem}}



%Put parentheses around the reference, as standard for equations
\newcommand{\req}[1]{(\ref{#1})}

%Short cut to make a column vector in math environment (centered)
\newcommand{\cvect}[1]{\left( \begin{array}{c} #1 \end{array} \right) }

%Short cut to make a column vector in math environment (right justified)
\newcommand{\rvect}[1]{\left( \begin{array}{r} #1 \end{array} \right) }

%A reference to a theorem. Prefix thm: is assumed for the label.
\newcommand{\refthm}[1]{theorem~\ref{thm:#1}}

%Reference to a figure. Prefix fig: is assumed for the label.
\newcommand{\reffig}[1]{Figure~\ref{fig:#1}}

%Smart reference to a figure. Prefix fig: is assumed for the label.
%\newcommand{\vreffig}[1]{Figure~\vref{fig:#1}}

%C in mathcal font for the choice set
\newcommand{\C}{\mathcal{C}}

%R in bold font for the set of real numbers
\newcommand{\R}{\mathbb{R}}

%N in bold font for the set of natural numbers
\newcommand{\N}{\mathbb{N}}

%C in mathcal font for the log likelihood
\renewcommand{\L}{\mathcal{L}}

%S in mathcal font for the subset S
\renewcommand{\S}{\mathcal{S}}

%To write an half in math envionment
\newcommand{\half}{\frac{1}{2}}

%Probability
\newcommand{\prob}{\operatorname{Pr}}

%Expectation
\newcommand{\expect}{\operatorname{E}}

%Variance
\newcommand{\var}{\operatorname{Var}}

%Covariance
\newcommand{\cov}{\operatorname{Cov}}

%Correlation
\newcommand{\corr}{\operatorname{Corr}}

%Span
\newcommand{\myspan}{\operatorname{span}}

%plim
\newcommand{\plim}{\operatorname{plim}}

%Displays n in bold (for the normal distribution?)
\newcommand{\n}{{\bf n}}

%Includes footnote in a table environment. Warning: the footmark is
%always 1.
\newcommand{\tablefootnote}[1]{\begin{flushright}
\rule{5cm}{1pt}\\
\footnotemark[1]{\footnotesize #1}
\end{flushright}
}

%Defines the ``th'' as in ``19th'' to be a superscript
\renewcommand{\th}{\textsuperscript{th}}

%Begin and end of a proof
\newcommand{\bpr}{{\bf Proof.} \hspace{1 em}}
\newcommand{\epr}{$\Box$}


\title{\PBIOGEME: a short introduction}
\author{Michel Bierlaire} 
\date{July 6, 2016}

\newcommand{\PBIOGEME}{PythonBiogeme}
\newcommand{\BIOGEME}{Biogeme}
\newcommand{\BBIOGEME}{BisonBiogeme}


\begin{document}


\begin{titlepage}
\pagestyle{empty}

\maketitle
\vspace{2cm}

\begin{center}
\small Report TRANSP-OR 160706 \\ Transport and Mobility Laboratory \\ School of Architecture, Civil and Environmental Engineering \\ Ecole Polytechnique F\'ed\'erale de Lausanne \\ \verb+transp-or.epfl.ch+
\begin{center}
\textsc{Series on Biogeme}
\end{center}
\end{center}


\clearpage
\end{titlepage}

The package Biogeme (\texttt{biogeme.epfl.ch}) is designed to estimate the parameters of
various models using maximum likelihood estimation. It is particularly
designed for discrete choice models. In this document, we present step
by step how to specify a simple model, estimate its parameters and
interpret the output of the software package.  We assume that the
reader is already familiar with discrete choice models, and has
successfully installed \PBIOGEME. This document has been written using
\PBIOGEME\ 2.5, but should remain valid for future versions.  

\section{The data file}

Biogeme assumes that the data file contains in its first line a list
of labels corresponding to the available data, and that each
subsequent line contains the exact same number of numerical data, each
row corresponding to an observation. Delimiters can be tabs or
spaces. The tool \lstinline$biopreparedata$ can be used to transform a
file in Comma Separated Version (CSV) into the required format. The
tool \lstinline$biocheckdata$ verifies if the data file complies with
the required format.


The data file used for this example is \texttt{swissmetro.dat}.
Note that the first time a data file is used by \BIOGEME, it is
compressed and saved in binary format in a file. The name of this file
is the same as the original file, preceeded by \lstinline$__bin_$. In
our example, the binary file is \lstinline$__bin_optima.dat$. If the
original text file is modifed, the binary file must be erased from the
directory in order to account for the changes. The name of the file
that has actually been used is reported in the 
output file.

\BIOGEME\ is available in two versions. \emph{BisonBiogeme} is designed to
estimate the parameters of a list of predetermined discrete choice
models such as logit, binary probit, nested logit, cross-nested logit,
multivariate extreme value models, discrete and continuous mixtures of
multivariate extreme value models, models with nonlinear utility
functions, models designed for panel data, and heteroscedastic
models. It is based on a formal and simple language for model
specification.
\emph{PythonBiogeme} is designed for general purpose parametric models. The
specification of the model and of the likelihood function is based on
an extension of the python programming language. A series of discrete
choice models are precoded for an easy use. 

In this document, we describe the model
specification for \PBIOGEME.

\section{The model}
The model is a logit model with 3 alternatives: \emph{train}, \emph{Swissmetro} and \emph{car}. The utility functions are defined as:
\begin{lstlisting}[style=nonumbers,backgroundcolor=]
V_1 = V_TRAIN =  ASC_TRAIN + B_TIME * TRAIN_TT_SCALED 
                           + B_COST * TRAIN_COST_SCALED
V_2 = V_SM = ASC_SM + B_TIME * SM_TT_SCALED 
                    + B_COST * SM_COST_SCALED
V_3 = V_CAR =  ASC_CAR + B_TIME * CAR_TT_SCALED 
                       + B_COST * CAR_CO_SCALED
\end{lstlisting}
where 
\lstinline@TRAIN_TT_SCALED@,
\lstinline@TRAIN_COST_SCALED@,
\lstinline@SM_TT_SCALED@,
\lstinline@SM_COST_SCALED@,
\lstinline@CAR_TT_SCALED@,
\lstinline@CAR_CO_SCALED@
are variables, and 
  \lstinline@ASC_TRAIN@,
  \lstinline@ASC_SM@,
  \lstinline@ASC_CAR@,
  \lstinline@B_TIME@,
  \lstinline@B_COST@ are parameters to be estimated. Note that it is not possible to identify all alternative specific constants  
  \lstinline@ASC_TRAIN@,
  \lstinline@ASC_SM@,
  \lstinline@ASC_CAR@ from data. Consequently,  \lstinline@ASC_SM@ is normalized to 0. 

The availability of an alternative \texttt{i} is determined by the
variable $y_i$, \texttt{i}=1,...3, which is equal to 1 if the
alternative is available, 0 otherwise. The probability of choosing an
available alternative \texttt{i} is given by the logit model: 
\begin{equation}
P(i|\{1,2,3\};x,\beta) = \frac{y_i e^{V_i(x,\beta)}}{y_1 e^{V_1(x,\beta)} + y_2 e^{V_2(x,\beta)}+ y_3 e^{V_3(x,\beta)}}.
\end{equation}
Given a data set of $N$ observations, the log likelihood of the
sample is 
\begin{equation}
\L = \sum_n \log P(i_n|\{1,2,3\};\beta)
\end{equation}
where $i_n$ is the alternative actually chosen
by individual $n$.  

\section{Model specification: \PBIOGEME}
\label{sec:mod}

The model specification file must have an extension \lstinline$.py$. 
The file \lstinline$01logit.py$ is reported in
Section~\ref{sec:modelPython}. We describe here its content. 

THe objective is to provide to \PBIOGEME\ the formula of the log
likelihood function to maximize, using a syntax based on the Python
programming language, and extended for the specific needs of \BIOGEME.
The file can
contain comments, designed to document the specification. 
Comments are included using the characters \verb+#+, consistently with
the Python syntax. All characters
after this command, up to the end of the current line, are ignored by \PBIOGEME.
In our example, the file starts with comments describing the name of
the file, its author and the date when it was created. A short
description of its content is also provided. 
\begin{lstlisting}[style=nonumbers]
########################################
#
# @file 01logit.py
# @author: Michel Bierlaire, EPFL
# @date: Wed Dec 21 13:23:27 2011
#
# Logit model
# Three alternatives: Train, Car and Swissmetro
# SP data
#
#######################################
\end{lstlisting}
These comments are
completely ignored by \PBIOGEME. However, it is recommended to use
many comments to describe the model specification, for future
reference, or to help other persons to understand the specification. 

The specification file must start by loading the Python libraries
needed by \PBIOGEME. Two libraries are mandatory \lstinline+biogeme+
and \lstinline+headers+. The first includes the extension of the
PYthon programming language needed by \PBIOGEME. The second imports
the names of the headers of the data file, so that they can be
directly used in the specification of the model. In this example, an
additional library is loaded as well: \lstinline+statistics+. It
implements some functions that report statistics about the data file. 

\begin{lstlisting}[style=nonumbers]
from biogeme import *
from headers import *
from statistics import *
\end{lstlisting}

The next statements use the function \lstinline+Beta+ to define the parameters to be estimated. For each parameter, the following information must be mentioned:
\begin{enumerate}
\item the name of the parameter,
\item the default value,
\item a lower bound,
\item an upper bound,
\item a flag that indicates if the parameter must be estimated (0) or
  if it keeps its default value (1),
\item a description of the parameter, to be used in the
  \LaTeX\ report. 
\end{enumerate}


Note that, in Python, case sensitivity is enforced, so that
\verb+varname+ and \verb+Varname+ would represent two different
variables.  In our example, the default value of each parameter is
0. If a previous estimation had been performed before, we could have
used the previous estimates as default value. Note that, for the
parameters that are estimated by \PBIOGEME, the default value is used
as the starting value for the optimization algorithm. For the
parameters that are not estimated, the default value is used
throughout the estimation process. In our example, the parameter
\lstinline$ASC_SM$ is not estimated (as specified by the \lstinline$1$
in the fifth argument on the corresponding line), and its value is
fixed to \lstinline$0$.  A lower bound and an upper bound must be
specified. By default, we suggest to use \lstinline$-1000$ and
\lstinline$1000$. If the estimated value of the parameter happens to
equal to one of these bounds, it is a sign that the bounds are too
tight and larger values should be provided. However, most of the time,
if a coefficient reaches the value 1000 or -1000, it means that its
variable is poorly scaled, and that its units should be changed.
\begin{lstlisting}[style=nonumbers]
ASC_CAR = Beta('ASC_CAR',0,-1000,1000,0,'Car cte.')
ASC_TRAIN = Beta('ASC_TRAIN',0,-1000,1000,0,'Train cte.')
ASC_SM = Beta('ASC_SM',0,-1000,1000,1,'Swissmetro cte.')
B_TIME = Beta('B_TIME',0,-1000,1000,0,'Travel time')
B_COST = Beta('B_COST',0,-1000,1000,0,'Travel cost')
\end{lstlisting}
Note that none of the Python variables is used by \PBIOGEME. They are
used only to simplify the writing of the formula. Therefore, nothing
prevents to write
\begin{lstlisting}[style=nonumbers]
car_cte = Beta('ASC_CAR',0,-1000,1000,0,'Car cte.')
\end{lstlisting}
and to use \lstinline+car_cte+ later in the specification. The
variable \lstinline+car_cte+ will be unknown by \PBIOGEME\ and will
not appear in any reporting file.   We
\textbf{strongly} advise against this practice, and suggest to use the
exact same name for the Python variable on the left hand side, and for
the PythonBiogeme variable, appearing as the first argument of the
function, as illustrated in this example. 

It is possible to define new variables in addition to the variables
defined in the data files. It can be done either by defining Python
variables using the Python syntax:
\begin{lstlisting}[style=nonumbers]
SM_COST =  SM_CO   * (  GA   ==  0  ) 
TRAIN_COST =  TRAIN_CO   * (  GA   ==  0  )
\end{lstlisting}
It can also be done by defining \PBIOGEME\ variables, using the
function \lstinline+DefineVariable+.
\begin{lstlisting}[style=nonumbers]
CAR_AV_SP =  DefineVariable('CAR_AV_SP',CAR_AV  * (  SP   !=  0  ))
TRAIN_AV_SP =  DefineVariable('TRAIN_AV_SP',TRAIN_AV  * (  SP   !=  0  ))
\end{lstlisting}
The latter definition is equivalent to add a column with the
specified header to the data file. It means that the value of the new
variables for each observation is calculated once before the
estimation starts. On the contrary, with the method based on Python
variable, the calculation will be applied again and again, each time
it is needed by the algorithm. For small models, it may not make any
difference, and the first method may be more readable. But for models
requiring a significant amount of time to be estimated, the time
savings may be substantial. 

When boolean expressions are involved, the value TRUE is
  represented by 1, and the value FALSE is represented by
  0. Therefore, a multiplication involving a boolean expression is
  equivalent to a ``AND'' operator. The above code is interpreted in
  the following way:
\begin{itemize}
\item \lstinline$CAR_AV_SP$ is equal to \lstinline$CAR_AV$ if
  \lstinline$SP$ is different from 0, and is equal to 0
  otherwise. \lstinline$TRAIN_AV_SP$ is defined similarly.
\item \lstinline$SM_COST$ is equal to \lstinline$SM_CO$ if
  \lstinline$GA$ is equal to 0, that is, if the traveler does not have
  a yearly pass (called ``general abonment''). If the traveler
  possesses a yearly pass, then \lstinline$GA$ is different from 0,
  and the variable \lstinline$SM_COST$ is zero. The variable
  \lstinline$TRAIN_COST$ is defined in the same way.
\end{itemize}

Variables can be also be rescaled. For numerical reasons, it is good
practice to scale the data so that the values of the estimated parameters are around 1.0. A previous estimation with the unscaled data has generated
parameters around -0.01 for both cost and time. Therefore, 
time and cost are divided by 100.

\begin{lstlisting}[style=nonumbers]
TRAIN_TT_SCALED = DefineVariable('TRAIN_TT_SCALED',\
   TRAIN_TT / 100.0)
TRAIN_COST_SCALED = DefineVariable('TRAIN_COST_SCALED',\
   TRAIN_COST / 100)
SM_TT_SCALED = DefineVariable('SM_TT_SCALED', SM_TT / 100.0)
SM_COST_SCALED = DefineVariable('SM_COST_SCALED', SM_COST / 100)
CAR_TT_SCALED = DefineVariable('CAR_TT_SCALED', CAR_TT / 100)
CAR_CO_SCALED = DefineVariable('CAR_CO_SCALED', CAR_CO / 100)
\end{lstlisting}

We now write the specification of the
utility functions.

\begin{lstlisting}[style=nonumbers]
V1 = ASC_TRAIN + \
     B_TIME * TRAIN_TT_SCALED + \
     B_COST * TRAIN_COST_SCALED
V2 = ASC_SM + \
     B_TIME * SM_TT_SCALED + \
     B_COST * SM_COST_SCALED
V3 = ASC_CAR + \
     B_TIME * CAR_TT_SCALED + \
     B_COST * CAR_CO_SCALED
\end{lstlisting}

We need to associate each utility function with the number of the
alternative, using the numering convention in the data file. In this
example, the convention is described in Table~\ref{tab:choice}. To do
this, we use a Python dictionary:
\begin{lstlisting}[style=nonumbers]
V = {1: V1,
     2: V2,
     3: V3}
\end{lstlisting}
We use also a dictionary to describe the availability conditions of
each alternative:
\begin{lstlisting}[style=nonumbers]
av = {1: TRAIN_AV_SP,
      2: SM_AV,
      3: CAR_AV_SP}
\end{lstlisting}

\begin{table}[htb]
\begin{center}
\begin{tabular}{rl}
Train & 1 \\
Swissmetro & 2 \\
Car & 3
\end{tabular}
\end{center}
\caption{\label{tab:choice}Numbering of the alternatives}
\end{table}

We now define the choice model. The function \lstinline+bioLogLogit+
provides the logarithm of the choice probability of the logit
model. It takes three arguments: 
\begin{enumerate}
\item the dictionary describing the utility functions,
\item the dictionary describing the availability conditions,
\item the alternative for which the probability must be calculated.
\end{enumerate}
In this example, we obtain
\begin{lstlisting}[style=nonumbers]
logprob = bioLogLogit(V,av,CHOICE)
\end{lstlisting}
We next defined an iterator on the data using the statement
\begin{lstlisting}[style=nonumbers]
rowIterator('obsIter') 
\end{lstlisting}
and define the \lstinline+ESTIMATE+ variable of the
\lstinline+BIOGEME_OBJECT+ with the formula of the log likelihood
function:
\begin{lstlisting}[style=nonumbers]
BIOGEME_OBJECT.ESTIMATE = Sum(logprob,'obsIter')
\end{lstlisting}

Other variables can be defined in the \lstinline+BIOGEME_OBJECT+. In
particular, the \lstinline+EXCLUDE+ variable allows to ignore some
observations in the data file. It contains a boolean expression that
is evaluated for each observation in the data file.  Each observation
such that this expression is ``true'' is discarded from the
sample. In our example, the modeler has developed the model only for
work trips, so that every observation such that the trip purpose is not 1
or 3 is removed.
Observations such that the dependent variable \lstinline$CHOICE$ is 0 are also
removed. Remember the convention that ``false'' is represented by 0,
and ``true'' by 1, so that the `*' can be interpreted as a ``and'',
and the `+' as a ``or''. Note also that the result of the `+' can be
2, so that we test is the result is equal to 0 or not. The exclude condition in our example is
therefore interpreted as: either (\lstinline$PURPOSE$ different from 1
and \lstinline$PURPOSE$ different from 3), or \lstinline$CHOICE$ equal
to 0. 

\begin{lstlisting}[style=nonumbers]
exclude = (( PURPOSE != 1 ) * (  PURPOSE   !=  3  ) + \
   ( CHOICE == 0 )) > 0
BIOGEME_OBJECT.EXCLUDE = exclude
\end{lstlisting}

Note that we have conveniently used an intermediary Python variable
\lstinline+exclude+ in this example. It is not necessary. The above
statement is completely equivalent to 
\begin{lstlisting}[style=nonumbers]
BIOGEME_OBJECT.EXCLUDE = \
   (( PURPOSE != 1 ) * (  PURPOSE   !=  3  ) + \
   ( CHOICE == 0 )) > 0
\end{lstlisting}

The variable \lstinline+PARAMETERS+ allows to define various
parameters controlling the configuration of \PBIOGEME. In this
example, we have selected to use the optimization algorithm
\lstinline+BIO+ using the following syntax.
\begin{lstlisting}[style=nonumbers]
BIOGEME_OBJECT.PARAMETERS['optimizationAlgorithm'] = "BIO"
\end{lstlisting}

The variable \lstinline+FORMULAS+ is used to select the parts of the
model specification that are reported in the report file. In general,
the formula of the log likelihood function is too complicated to be
readable, and it is preferred to report only the specification of the
utility functions, as in this example.
\begin{lstlisting}[style=nonumbers]
BIOGEME_OBJECT.FORMULAS['Train utility'] = V1
BIOGEME_OBJECT.FORMULAS['Swissmetro utility'] = V2
BIOGEME_OBJECT.FORMULAS['Car utility'] = V3
\end{lstlisting}

Finally, we request \PBIOGEME\ to calculate some statistics about the
null log likelihood, the log likelihood of a model with constants
only, and statistics about the availability of the alternatives. 

\begin{lstlisting}[style=nonumbers]
nullLoglikelihood(av,'obsIter')
choiceSet = [1,2,3]
cteLoglikelihood(choiceSet,CHOICE,'obsIter')
availabilityStatistics(av,'obsIter')
\end{lstlisting}

The function \lstinline+nullLoglikelihood+ computes the null loglikelihood from the sample and ask \PBIOGEME\ to include it in the output file.
The first argument is a dictionary  mapping each alternative ID with
its availability condition. The second is an iterator on the data file.
The result is the log likelihood of a model where the choice probability for
 observation $n$ is given by is $1/J_n$, where $J_n$ is
 the number of available alternatives, i.e. 
\begin{equation}
 \mathcal{L} = -\sum_n \ln(J_n).
\end{equation}


The function \lstinline+cteLoglikelihood+ computes the constant loglikelihood from the sample and ask \PBIOGEME\ to include it in the output file. It assumes that the full choice set is available for each observation.
The first argument is a list containing the alternatives in the choice set.
The second argument is the choice expression producing the id of the
chosen alternative. The third argument is an iterator on the data file.
The result is the log likelihood of a logit model where the only
parameters are the alternative specific constants. If $n_i$ is the
number of times alternative $i$ is chosen, then it is given by 
\begin{equation}
 \mathcal{L} = \sum_i n_i \ln(n_i) - n \ln(n) 
\end{equation}
where $n = \sum_i n_i$ is the total number of observations.

The function \lstinline+availabilityStatistics+ computes the number of
times each alternative is declared available in the data set and ask
\PBIOGEME\ to include it in the output file.
The first argument is a dictionary containing for each alternative the
expression for its availability. The second is  an iterator on the
data file. The result is a dictionary \lstinline+D+ with an entry \lstinline+D[i]+ for each
alternative i containing the number of times it is available.

\section{Running \PBIOGEME}

The estimation of the model is performed using the following command 
\begin{lstlisting}
pythonbiogeme 01logit swissmetro.dat
\end{lstlisting}

The following information is displayed during the execution.
\begin{itemize}
\item Some information about the version of Biogeme.
\begin{lstlisting}
This is biogeme (pythonbiogeme) 2.5
\end{lstlisting}
\item The name of the sample file that is read.
\begin{lstlisting}
 Read sample file: swissmetro.dat
\end{lstlisting}
\item \PBIOGEME\ is able to use several processors if they are
  available. By default, it uses half of the number fo available
  processors on the computer. 
\begin{lstlisting}
 Nbr of cores reported by the system: 4
 Nbr of cores used by biogeme: 2
\end{lstlisting}
\item The details about the iterations of the estimation procedure are
  reported. 
\begin{lstlisting}[style=tiny]
 Init. log-likelihood: -6964.66 [00:00]
     gmax Iter   radius        f(x)     Status       rhok nFree
 +1.44e-01    1 1.00e+00 +6.9646630e+03 ****Converg  +1.07e+00 4  ++ P
 +5.29e-02    2 2.00e+00 +5.4217993e+03 ****Converg  +1.08e+00 4  ++ P
 +9.43e-03    3 4.00e+00 +5.3328087e+03 ****Converg  +1.02e+00 4  ++ P
 +2.34e-04    4 8.00e+00 +5.3312529e+03 ****Converg  +1.00e+00 4  ++ P

 Convergence reached...
--> time interval [16:28:46,16:28:46]
\end{lstlisting}
\item The value of the parameters at the end of the iterarions.
\begin{lstlisting}
 Estimated parameters: 
ASC_CAR = -0.154633
B_TIME = -1.27786
B_COST = -1.08379
ASC_SM = 0
ASC_TRAIN = -0.701187
\end{lstlisting}
\end{itemize}
The following files are generated by \PBIOGEME:
\begin{itemize}
\item \lstinline$01logit.html$: the results of the estimation in Html
  format. Its content is described in Section~\ref{sec:pythonreport}.
\item \lstinline$01logit_param.py$: the estimated value of the
  parameters, together with the variance-covariance matrix of the
  estimates, in a syntax that can be directly reused in a model
  specification file.
\item \lstinline$01logit.log$: a file containing messages produced by \PBIOGEME\ during the run.
\item \lstinline$01logit.tex$: a file containing the main results in
  \LaTeX\ format. See Table~\ref{tab:latex}.
\item \lstinline$hess.lis$: contains the final BHHH and the second
  derivative, or Hessian, matrix. The format is such that it can be
  copied and pasted in a matrix language such as Matlab or Octave. 
\item \lstinline$hessian.lis$: contains the (opposite of the) Hessian
  matrix of the log likelihood function at each iteration, in a Matlab
  compatible format. 
\item \lstinline$__parametersUsed.py$: provides an exhaustive list of the
  parameters used by the run of \PBIOGEME, together with the value
  that has been used. 
\end{itemize}

In order to avoid erasing previously generated results, the name of
the files may vary from one run to the next. Therefore,
\PBIOGEME\ explicitly mentions the name of the main files that have
been generated. 

\begin{lstlisting}
 File 01logit_param.py created
 File 01logit.html has been generated
 File 01logit.tex has been generated
\end{lstlisting}

\begin{table}[htb]
\footnotesize
  \begin{tabular}{l}
\begin{tabular}{rlr@{.}lr@{.}lr@{.}lr@{.}l}
         &                       &   \multicolumn{2}{l}{}    & \multicolumn{2}{l}{Robust}  &     \multicolumn{4}{l}{}   \\
Parameter &                       &   \multicolumn{2}{l}{Coeff.}      & \multicolumn{2}{l}{Asympt.}  &     \multicolumn{4}{l}{}   \\
number &  Description                     &   \multicolumn{2}{l}{estimate}      & \multicolumn{2}{l}{std. error}  &   \multicolumn{2}{l}{$t$-stat}  &   \multicolumn{2}{l}{$p$-value}   \\

\hline

1 & Car cte. & -0&155 & 0&0582 & -2&66 & 0&01\\
2 & Train cte. & -0&701 & 0&0826 & -8&49 & 0&00\\
3 & Travel cost & -1&08 & 0&0682 & -15&89 & 0&00\\
4 & Travel time & -1&28 & 0&104 & -12&26 & 0&00\\
\hline
\end{tabular}
\\
\begin{tabular}{rcl}
\multicolumn{3}{l}{\bf Summary statistics}\\
\multicolumn{3}{l}{ Number of observations = $6768$} \\
\multicolumn{3}{l}{ Number of excluded observations = $3960$} \\
\multicolumn{3}{l}{ Number of estimated  parameters = $4$} \\
 $\mathcal{L}(\beta_0)$ &=&  $-6964.663$ \\
 $\mathcal{L}(\hat{\beta})$ &=& $-5331.252 $  \\
 $-2[\mathcal{L}(\beta_0) -\mathcal{L}(\hat{\beta})]$ &=& $3266.822$ \\
    $\rho^2$ &=&   $0.235$ \\
    $\bar{\rho}^2$ &=&    $0.234$ \\
\end{tabular}
  \end{tabular}
\caption{\label{tab:latex}Results of the estimation in \LaTeX}
\end{table}


\clearpage
\section{\PBIOGEME: the report file}
\label{sec:pythonreport}

The report file generated by \PBIOGEME\ gathers various information
about the result of the estimation. First, some information about the
version of Biogeme, and some links to relevant URLs is provided. 
Next, the name of the report file and the sample file are reported. 

If some formulas have been requested to be reported, it is done in the
next section. 
After is a list of statistics requested in the model specification
file.
The estimation report follows, including
   \begin{itemize}
      \item The number of parameters that have been estimated.
      \item The number of observations, that is, the number of rows in
        the data file  that have not been excluded.
      \item The number of excluded observations.
      \item \lstinline+Init log likelihood+ is the log likelihood
        $\mathcal{L}^i$ of
        the sample for the model defined with the default values of
        the parameters.
      \item \lstinline+Final log likelihood+ is the log likelihood
        $\mathcal{L}^*$ of the sample for the estimated model. 
      \item \lstinline+Likelihood ratio test for the init. model+ is 
         \begin{equation}
            -2 ( \mathcal{L}^i - \mathcal{L}^*)
         \end{equation}
         where 
         $ \mathcal{L}^i$ is the null log likelihood of the init model
         as defined above, and $\mathcal{L}^*$ is the log likelihood of the sample for the estimated model. 
      \item \lstinline+Rho-square+ is
         \begin{equation}
            \rho^2 = 1 - \frac{\mathcal{L}^*}{\mathcal{L}^i}.
         \end{equation}
        \item \lstinline+Rho-square-bar+ is
         \begin{equation}
            \rho^2 = 1 - \frac{\mathcal{L}^* - K}{\mathcal{L}^i}.
         \end{equation}
         where $K$ is the number of estimated parameters. Note that this statistic is meaningless in the presence of constraints, where the number of degrees of freedom is less than  the number of parameters. 
      \item \lstinline+Final gradient norm+ is the gradient of the log
        likelihood function computed for the estimated parameters. If
        no constraint is active at the solution, it should be close to
        0. If there are equality constraints, or if some bound
        constraints or inequality constraints are active at the
        solution (that is, they are verified with equality), the
        gradient may not be close to zero.
\item \lstinline+Diagnostic+ is the diagnostic reported by the optimization
algorithm. If the algorithm has not converged, the estimation results presented
in the file cannot be used as such. 
\item \lstinline+Iterations+ is the number of iterations used by the
algorithm before it stopped. 
\item \lstinline+Run time+ is the actual time used by the algorithm before
it stopped, in minutes and seconds (format \texttt{mm:ss}).
\item \lstinline+Nbr of thread+: number of threads that is of
  processors, used during the estimation. 
   \end{itemize}


The following section reports the estimates of the parameters of the
utility function,
together with some statistics. For each parameter $\beta_k$, the following is reported:
   \begin{itemize}
  \item The name of the parameter.
      \item The estimated value $\beta_k$. 
      \item The standard error $\sigma_k$ of the estimate, calculated as the
         square root of the $k$\th diagonal entry of the
         Rao-Cramer bound (see Appendix~\ref{sec:robust}).
     \item The $t$ statistics, calculated as $t_k=\beta_k/\sigma_k$.
     \item The $p$ value, calculated as $2 (1 - \Phi(t_k))$,
where $\Phi(\cdot)$ is the cumulative density function of the
univariate standard normal distribution. 
     \item  A sign \lstinline$*$ is
         appended if the absolute value value of $t_k$ is less than
         1.96, emphasizing a potential lack of statistical
         significance. In this example, no such sign appears. 
      \item The robust standard error $\sigma^R_k$ of the estimate, calculated as the
         square root of the $k$\th diagonal entry of the
         robust estimate of the variance covariance matrix. (see Appendix~\ref{sec:robust}).
     \item The robust $t$ statistics, calculated as $t^R_k=\beta_k/\sigma^R_k$.
     \item The robust $p$ value, calculated as $2 (1 - \Phi(t^R_k))$,
where $\Phi(\cdot)$ is the cumulative density function of the
univariate normal distribution. 
     \item  A sign \lstinline$*$ is
         appended if the absolute value value of $t^R_k$ is less than
         1.96, emphasizing a potential lack of statistical
         significance. In this example, no such sign appears. 
   \end{itemize}




The last section reports, for each pair of parameters $k$ and
$\ell$,
\begin{itemize}
\item the name of $\beta_k$,
\item the name of $\beta_\ell$,
\item the entry $\Sigma_{k,\ell}$ of the 
         Rao-Cramer bound (see Appendix~\ref{sec:robust}),
\item the correlation between $\beta_k$ and $\beta_\ell$, calculated as
\begin{equation}
\frac{\Sigma_{k,\ell}}{\sqrt{\Sigma_{k,k}\Sigma_{\ell,\ell}}},
\end{equation}
\item the $t$ statistics, calculated as
\begin{equation}
t_{k,\ell}= \frac{\beta_k - \beta_\ell}{\sqrt{\Sigma_{k,k} + \Sigma_{\ell,\ell} - 2 \Sigma_{k,\ell}}},
\end{equation}
  \item  a sign \lstinline$*$ is
         appended if the absolute value value of $t_{k,\ell}$ is less than
         1.96, emphasizing that the hypothesis that the two parameters
         are equal cannot be rejected at the 5\% level (in this example, no such sign appears), 
\item the entry $\Sigma^R_{k,\ell}$ of $\Sigma^R$, the robust estimate of the variance covariance matrix (see Appendix~\ref{sec:robust}),
\item the robust correlation between $\beta_k$ and $\beta_\ell$, calculated as
\begin{equation}
\frac{\Sigma^R_{k,\ell}}{\sqrt{\Sigma^R_{k,k}\Sigma^R_{\ell,\ell}}},
\end{equation}
\item the robust $t$ statistics, calculated as
\begin{equation}
t^R_{k,\ell}=\frac{\beta_k - \beta_\ell}{\sqrt{\Sigma^R_{k,k} + \Sigma^R_{\ell,\ell}
    - 2 \Sigma^R_{k,\ell}}},
\end{equation}
  \item  a sign \lstinline$*$ is
         appended if the absolute value value of $t^R_{k,\ell}$ is less than
         1.96, emphasizing that the hypothesis that the two parameters
         are equal cannot be rejected at the 5\% level (in this
         example, one such sign appears, for parameters
         \lstinline$B_COST$ and \lstinline$B_TIME$). 
\end{itemize}
The final line reports the value of the smallest singular value of the
second derivatives matrix. A value close to zero is a sign of
singularity, that may be due to a lack of variation in the data or
an unidentified model.


\clearpage 


\appendix

\section{Complete specification file}

\subsection{\lstinline$01logit.py$}
\label{sec:modelPython}
\lstinputlisting[style=numbers,basicstyle=\footnotesize]{../../../test/swissmetro/01logit.py}

\clearpage

   \section{Estimation of the  variance-covariance matrix}
   \label{sec:robust}
Under relatively general conditions,  the asymptotic
variance-covariance matrix of the maximum likelihood
estimates of the vector of parameters $\theta \in \R^K$ is given by the Cramer-Rao bound
\begin{equation}
  \label{eq:RaoCramer}
  -\expect\left[ \nabla^2 \L(\theta)\right]^{-1} =  \left\{-\expect\left[\frac{\partial^2 \L(\theta)}{\partial \theta \partial \theta^T}\right]\right\}^{-1}.
\end{equation}
The term in square brackets is the matrix of the second derivatives
of the log likelihood function with respect to the parameters
evaluated at the true parameters.  Thus the entry in the $k$\/th row and
the $\ell$\/th column is
\begin{equation}
  \label{eq:BAL4.34}
 \frac{\partial^2 \L(\theta)}{\partial \theta_k \partial \theta_{\ell}}.
\end{equation}

Since we do not know the actual values of the parameters at which to
evaluate the second derivatives, or the distribution of $x_{in}$ and
$x_{jn}$ over which to take their expected value, we estimate the
variance-covariance matrix by evaluating the second derivatives  at the estimated parameters
$\hat{\theta}$ and the sample distribution of $x_{in}$ and $x_{jn}$ instead of
 their true distribution. Thus we use
\begin{equation}
  \label{eq:BAL4.35}
  \expect\left[\frac{\partial^2 \L(\theta)}{\partial \theta_k \partial \theta_\ell}  \right]\approx \sum_{n=1}^N \left[\frac{\partial^2\left(y_{in}\ln P_n(i) + y_{jn} \ln P_n(j) \right)}{\partial \theta_k \partial \theta_\ell} \right]_{\theta=\hat{\theta}},
\end{equation}
as a consistent estimator of the matrix of second derivatives. 

Denote
this matrix as $\hat{A}$. Note that, from the second order optimality conditions of the optimization
problem, this matrix is negative semi-definite, which is the algebraic equivalent of the local  concavity of the
log likelihood function.
 If the maximum is unique, the matrix is negative definite, and the
 function is locally strictly concave. 




 An estimate of the Cramer-Rao
bound \req{eq:RaoCramer} is given by 
\begin{equation}
\label{eq:EstimateRaoCramer}
\widehat{\Sigma}^{\text{CR}}_{\theta} = -\hat{A}^{-1}.
\end{equation}
If  the matrix $\hat{A}$ is  negative definite then $-\hat{A}$ is invertible and the Cramer-Rao bound is positive definite. 

Another consistent estimator of the (negative of the) second
derivatives matrix can be obtained by the matrix of the cross-products of first derivatives as follows:
\begin{equation}
\label{eq:binaryBHHH}
-E\left[ \frac{\partial^2 \L(\theta)}{\partial \theta \partial \theta^T}\right] \approx  \sum_{n=1}^n \left(\frac{\partial \ell_n(\hat{\theta})}{\partial \theta} \right)\left(\frac{\partial \ell_n(\hat{\theta})}{\partial \theta} \right)^T = \hat{B},
\end{equation}
 where
\begin{equation}
\left(\frac{\partial \ell_n(\hat{\theta})}{\partial \theta} \right) = \frac{\partial}{\partial \theta} (\log P(i_n|\C_n;\widehat{\theta}))
\end{equation}
is the gradient vector of the likelihood of observation $n$.
This approximation is employed by the BHHH algorithm, from the work by \citeasnoun{BernHallHallHaus74}. Therefore, an estimate of the variance-covariance matrix 
is given by 
\begin{equation}
\widehat{\Sigma}^{\text{BHHH}}_{\theta} =\hat{B}^{-1},
\end{equation}
 although it is rarely used. 
Instead, $\hat{B}$ is
used to derive  a third consistent estimator of the variance-covariance matrix of
the parameters, defined as
\begin{equation}
\label{eq:robustEstimator}
\widehat{\Sigma}^{\text{R}}_{\theta} = (-\hat{A})^{-1} \; \widehat{B}\; (-\hat{A})^{-1} = \widehat{\Sigma}^{\text{CR}}_{\theta} \; (\widehat{\Sigma}^{\text{BHHH}}_{\theta})^{-1} \; \widehat{\Sigma}^{\text{CR}}_{\theta}.
\end{equation}

It is
called the \emph{robust} estimator, or sometimes the \emph{sandwich}
estimator, due to the form of equation
\req{eq:robustEstimator}. \BIOGEME\ reports statistics based on  both the Cramer-Rao estimate
\req{eq:EstimateRaoCramer} and the robust estimate \req{eq:robustEstimator}.


 When the true likelihood function is maximized,  these estimators are
 asymptotically equivalent, and the Cramer-Rao bound should be
preferred (\cite{KaueCarr2001}).  When other consistent estimators are
used, the robust estimator must be used
(\cite{Whit82}). Consistent non-maximum likelihood estimators, known
as pseudo maximum likelihood estimators, are often used when the true
likelihood function is unknown or difficult to compute. In such cases,
it is often possible to obtain consistent estimators by maximizing an
objective function based on a simplified probability distribution. 

\bibliographystyle{dcu}
\bibliography{../dca}





\end{document}





