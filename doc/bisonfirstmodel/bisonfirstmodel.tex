\documentclass[12pt,a4paper]{article}

% Package to include code
\usepackage{listings}
\usepackage{color}
\lstset{language=Python}
\lstset{numbers=none, basicstyle=\footnotesize\ttfamily,
  numberstyle=\tiny,keywordstyle=\color{blue},stringstyle=\ttfamily,showstringspaces=false}
\lstset{backgroundcolor=\color[rgb]{0.95 0.95 0.95}}
\lstdefinestyle{numbers}{numbers=left, stepnumber=1, numberstyle=\tiny, numbersep=10pt,basicstyle=\footnotesize\ttfamily}
\lstdefinestyle{nonumbers}{numbers=none,basicstyle=\footnotesize\ttfamily}
\lstdefinestyle{tiny}{numbers=none,basicstyle=\tiny\ttfamily}

% Font selection: uncomment the next line to use the ``beton'' font
%\usepackage{beton}

% Font selection: uncomment the next line to use the ``times'' font
%\usepackage{times}

% Font for equations
\usepackage{euler}


%Package to define the headers and footers of the pages
\usepackage{fancyhdr}


%Package to include an index
\usepackage{index}

%Package to display boxes around texts. Used especially for the internal notes.
\usepackage{framed}

%PSTricks is a collection of PostScript-based TEX macros that is compatible
% with most TEX macro packages
\usepackage{pstricks}
\usepackage{pst-node}
\usepackage{pst-plot}
\usepackage{pst-tree}

%Package to display boxes around a minipage. Used especially to
%describe the biography of people.
\usepackage{boxedminipage}

%Package to include postscript figures
\usepackage{epsfig}

%Package for the bibliography
% \cite{XXX} produces Ben-Akiva et. al., 2010
% \citeasnoun{XXX} produces Ben-Akiva et al. (2010)
% \citeasnoun*{XXX} produces Ben-Akiva, Bierlaire, Bolduc and Walker (2010)
\usepackage[dcucite,abbr]{harvard}
\harvardparenthesis{none}\harvardyearparenthesis{round}

%Packages for advanced mathematics typesetting
\usepackage{amsmath,amsfonts,amssymb}

%Package to display trees easily
%\usepackage{xyling}

%Package to include smart references (on the next page, on the
%previous page, etc.) 
%%

%% Remove as it is not working when the book will be procesed by the
%% publisher.
%\usepackage{varioref}

%Package to display the euro sign
\usepackage[right,official]{eurosym}

%Rotate material, especially large table (defines sidewaystable)
\usepackage[figuresright]{rotating}

%Defines the subfigure environment, to obtain refs like Figure 1(a)
%and Figure 1(b). 
\usepackage{subfigure}

%Package for appendices. Allows subappendices, in particular
\usepackage{appendix}

%Package controling the fonts for the captions
\usepackage[font={small,sf}]{caption}

%Defines new types of columns for tabular ewnvironment
\usepackage{dcolumn}
\newcolumntype{d}{D{.}{.}{-1}}
\newcolumntype{P}[1]{>{#1\hspace{0pt}\arraybackslash}}
\newcolumntype{.}{D{.}{.}{9.3}}

%Allows multi-row cells in tables
\usepackage{multirow}

%Tables spaning more than one page
\usepackage{longtable}


%%
%%  Macros by Michel
%%

%Internal notes
\newcommand{\note}[1]{
\begin{framed}{}%
\textbf{\underline{Internal note}:} #1
\end{framed}}

%Use this version to turn off the notes
%\newcommand{\note}[1]{}


%Include a postscript figure . Note that the label is prefixed with
%``fig:''. Remember it when you refer to it.  
%Three arguments:
% #1 label
% #2 file (without extension)
% #3 Caption
\newcommand{\afigure}[3]{%
\begin{figure}[!tbp]%
\begin{center}%
\epsfig{figure=#2,width=0.8\textwidth}%
\end{center}
\caption{\label{fig:#1} #3}%
\end{figure}}






%Include two postscript figures side by side. 
% #1 label of the first figure
% #2 file for the first figure
% #3 Caption for the first figure
% #4 label of the second figure
% #5 file for the second figure
% #6 Caption for the first figure
% #7 Caption for the set of two figures
\newcommand{\twofigures}[7]{%
\begin{figure}[htb]%
\begin{center}%
\subfigure[\label{fig:#1}#3]{\epsfig{figure=#2,width=0.45\textwidth}}%
\hfill
\subfigure[\label{fig:#4}#6]{\epsfig{figure=#5,width=0.45\textwidth}}%
\end{center}
\caption{#7}%
\end{figure}}

%Include a figure generated by gnuplot using the epslatex output. Note that the label is prefixed with
%``fig:''. Remember it when you refer to it.  
 
%Three arguments:
% #1 label
% #2 file (without extension)
% #3 Caption
\newcommand{\agnuplotfigure}[3]{%
\begin{figure}[!tbp]%
\begin{center}%
\input{#2}%
\end{center}
\caption{\label{fig:#1} #3}%
\end{figure}}

%Three arguments:
% #1 label
% #2 file (without extension)
% #3 Caption
\newcommand{\asidewaysgnuplotfigure}[3]{%
\begin{sidewaysfigure}[!tbp]%
\begin{center}%
\input{#2}%
\end{center}
\caption{\label{fig:#1} #3}%
\end{sidewaysfigure}}


%Include two postscript figures side by side. 
% #1 label of the first figure
% #2 file for the first figure
% #3 Caption for the first figure
% #4 label of the second figure
% #5 file for the second figure
% #6 Caption for the second figure
% #7 Caption for the set of two figures
% #8 label for the whole figure
\newcommand{\twognuplotfigures}[7]{%
\begin{figure}[htb]%
\begin{center}%
\subfigure[\label{fig:#1}#3]{\input{#2}}%
\hfill
\subfigure[\label{fig:#4}#6]{\input{#5}}%
\end{center}
\caption{#7}%
\end{figure}}



%Include the description of somebody. Four arguments:
% #1 label
% #2 Name
% #3 file (without extension)
% #4 description
\newcommand{\people}[4]{
\begin{figure}[tbf]
\begin{boxedminipage}{\textwidth}
\parbox{0.40\textwidth}{\epsfig{figure=#3,width = 0.39\textwidth}}%\hfill
\parbox{0.59\textwidth}{%
#4% 
}%
\end{boxedminipage}
\caption{\label{fig:#1} #2}
\end{figure}
}

%Default command for a definition
% #1 label (prefix def:)
% #2 concept to be defined
% #3 definition
\newtheorem{definition}{Definition}
\newcommand{\mydef}[3]{%
\begin{definition}%
\index{#2|textbf}%
\label{def:#1}%
\textbf{#2} \slshape #3\end{definition}}

%Reference to a definitoin. Prefix 'def:' is assumed
\newcommand{\refdef}[1]{definition~\ref{def:#1}}


%Default command for a theorem, with proof
% #1: label (prefix thm:)
% #2: name of the theorem
% #3: statement
% #4: proof
\newtheorem{theorem}{Theorem}
\newcommand{\mytheorem}[4]{%
\begin{theorem}%
\index{#2|textbf}%
\index{Theorems!#2}%
\label{thm:#1}%
\textbf{#2} \sffamily \slshape #3
\end{theorem} \bpr #4 \epr \par}


%Default command for a theorem, without proof
% #1: label (prefix thm:)
% #2: name of the theorem
% #3: statement
\newcommand{\mytheoremsp}[3]{%
\begin{theorem}%
\index{#2|textbf}%
\index{Theorems!#2}%
\label{thm:#1}%
\textbf{#2} \sffamily \slshape #3
\end{theorem}}



%Put parentheses around the reference, as standard for equations
\newcommand{\req}[1]{(\ref{#1})}

%Short cut to make a column vector in math environment (centered)
\newcommand{\cvect}[1]{\left( \begin{array}{c} #1 \end{array} \right) }

%Short cut to make a column vector in math environment (right justified)
\newcommand{\rvect}[1]{\left( \begin{array}{r} #1 \end{array} \right) }

%A reference to a theorem. Prefix thm: is assumed for the label.
\newcommand{\refthm}[1]{theorem~\ref{thm:#1}}

%Reference to a figure. Prefix fig: is assumed for the label.
\newcommand{\reffig}[1]{Figure~\ref{fig:#1}}

%Smart reference to a figure. Prefix fig: is assumed for the label.
%\newcommand{\vreffig}[1]{Figure~\vref{fig:#1}}

%C in mathcal font for the choice set
\newcommand{\C}{\mathcal{C}}

%R in bold font for the set of real numbers
\newcommand{\R}{\mathbb{R}}

%N in bold font for the set of natural numbers
\newcommand{\N}{\mathbb{N}}

%C in mathcal font for the log likelihood
\renewcommand{\L}{\mathcal{L}}

%S in mathcal font for the subset S
\renewcommand{\S}{\mathcal{S}}

%To write an half in math envionment
\newcommand{\half}{\frac{1}{2}}

%Probability
\newcommand{\prob}{\operatorname{Pr}}

%Expectation
\newcommand{\expect}{\operatorname{E}}

%Variance
\newcommand{\var}{\operatorname{Var}}

%Covariance
\newcommand{\cov}{\operatorname{Cov}}

%Correlation
\newcommand{\corr}{\operatorname{Corr}}

%Span
\newcommand{\myspan}{\operatorname{span}}

%plim
\newcommand{\plim}{\operatorname{plim}}

%Displays n in bold (for the normal distribution?)
\newcommand{\n}{{\bf n}}

%Includes footnote in a table environment. Warning: the footmark is
%always 1.
\newcommand{\tablefootnote}[1]{\begin{flushright}
\rule{5cm}{1pt}\\
\footnotemark[1]{\footnotesize #1}
\end{flushright}
}

%Defines the ``th'' as in ``19th'' to be a superscript
\renewcommand{\th}{\textsuperscript{th}}

%Begin and end of a proof
\newcommand{\bpr}{{\bf Proof.} \hspace{1 em}}
\newcommand{\epr}{$\Box$}


\title{\BBIOGEME: estimating a first model}
\author{Michel Bierlaire} 
\date{July 20, 2015}

\newcommand{\PBIOGEME}{PythonBiogeme}
\newcommand{\BIOGEME}{Biogeme}
\newcommand{\BBIOGEME}{BisonBiogeme}


\begin{document}


\begin{titlepage}
\pagestyle{empty}

\maketitle
\vspace{2cm}

\begin{center}
\small Report TRANSP-OR 150720 \\ Transport and Mobility Laboratory \\ School of Architecture, Civil and Environmental Engineering \\ Ecole Polytechnique F\'ed\'erale de Lausanne \\ \verb+transp-or.epfl.ch+
\begin{center}
\textsc{Series on Biogeme}
\end{center}
\end{center}


\clearpage
\end{titlepage}

The package Biogeme (\texttt{biogeme.epfl.ch}) is designed to estimate the parameters of
various models using maximum likelihood estimation. It is particularly
designed for discrete choice models. In this document, we present step
by step how to specify a simple model, estimate its parameters and
interpret the output of the software package.  We assume that the
reader is already familiar with discrete choice models, and has
successfully installed \BBIOGEME. This document has been written using
\BBIOGEME\ 2.4, but should be valid for future versions, as no major
release if foreseen. 

\section{The data file}

Biogeme assumes that the data file contains in its first line a list
of labels corresponding to the available data, and that each
subsequent line contains the exact same number of numerical data, each
row corresponding to an observation. Delimiters can be tabs or
spaces. The tool \lstinline$biopreparedata$ can be used to transform a
file in Comma Separated Version (CSV) into the required format. The
tool \lstinline$biocheckdata$ verifies if the data file complies with
the required format.

The data file used for this example is \texttt{swissmetro.dat}.
\BIOGEME\ is available in two versions. \emph{BisonBiogeme} is designed to
estimate the parameters of a list of predetermined discrete choice
models such as logit, binary probit, nested logit, cross-nested logit,
multivariate extreme value models, discrete and continuous mixtures of
multivariate extreme value models, models with nonlinear utility
functions, models designed for panel data, and heteroscedastic
models. It is based on a formal and simple language for model
specification.
\emph{PythonBiogeme} is designed for general purpose parametric models. The
specification of the model and of the likelihood function is based on
an extension of the python programming language. A series of discrete
choice models are precoded for an easy use. 

In this document, we describe the model
specification for \BBIOGEME.

\section{The model}
The model is a logit model with 3 alternatives: \emph{train}, \emph{Swissmetro} and \emph{car}. The utility functions are defined as:
\begin{lstlisting}[style=nonumbers,backgroundcolor=]
V_1 = V_TRAIN =  ASC_TRAIN + B_TIME * TRAIN_TT_SCALED 
                           + B_COST * TRAIN_COST_SCALED
V_2 = V_SM = ASC_SM + B_TIME * SM_TT_SCALED 
                    + B_COST * SM_COST_SCALED
V_3 = V_CAR =  ASC_CAR + B_TIME * CAR_TT_SCALED 
                       + B_COST * CAR_CO_SCALED
\end{lstlisting}
where 
\lstinline@TRAIN_TT_SCALED@,
\lstinline@TRAIN_COST_SCALED@,
\lstinline@SM_TT_SCALED@,
\lstinline@SM_COST_SCALED@,
\lstinline@CAR_TT_SCALED@,
\lstinline@CAR_CO_SCALED@
are variables, and 
  \lstinline@ASC_TRAIN@,
  \lstinline@ASC_SM@,
  \lstinline@ASC_CAR@,
  \lstinline@B_TIME@,
  \lstinline@B_COST@ are parameters to be estimated. Note that it is not possible to identify all alternative specific constants  
  \lstinline@ASC_TRAIN@,
  \lstinline@ASC_SM@,
  \lstinline@ASC_CAR@ from data. Consequently,  \lstinline@ASC_SM@ is normalized to 0. 

The availability of an alternative \texttt{i} is determined by the
variable $y_i$, \texttt{i}=1,...3, which is equal to 1 if the
alternative is available, 0 otherwise. The probability of choosing an
available alternative \texttt{i} is given by the logit model: 
\begin{equation}
P(i|\{1,2,3\};x,\beta) = \frac{y_i e^{V_i(x,\beta)}}{y_1 e^{V_1(x,\b)} + y_2 e^{V_2}+ y_3 e^{V_3}}.
\end{equation}
Given a data set of $N$ observations, the log likelihood of the
sample is 
\begin{equation}
\L = \sum_n \log P(i_n|\{1,2,3\};\beta)
\end{equation}
where $i_n$ is the alternative actually chosen
by individual $n$.  

\section{Model specification: \BBIOGEME}
\label{sec:mod}

The model specification file must have an extension \lstinline$.mod$. 
The file \lstinline$01logit.mod$ is reported in
Section~\ref{sec:modelBison}. We describe here its content. 

The model specification is organized into sections. The order in which
the sections appear in the file is not important for \BBIOGEME. Each section
starts with the name of the section within square brackets, such as
\lstinline$[ModelDescription]$ or \lstinline$[Choice]$. The file can
contain also comments, designed to document the specification. 
Comments are included using the characters \verb+//+. All characters
after this command, up to the end of the current line, are ignored by \BBIOGEME.
In our example, the file starts with comments describing the name of
the file, its author and the date when it was created. A short
description of its content is also provided. 
\begin{lstlisting}[style=nonumbers]
// File: 01logit.mod
// Author: Michel Bierlaire, EPFL
// Date: Fri Nov 12 16:43:52 2010
//
// Logit model
// Three alternatives: Train, Car and Swissmetro
// SP data
\end{lstlisting}
These comments are
completely ignored by \BBIOGEME. However, it is recommended to use
many comments to describe the model specification, for future
reference, or to help other persons to understand the specification. 

The first section in \lstinline$01logit.mod$ is
\lstinline$[ModelDescription]$.  It allows to mention a description of
the model that will be copied in the report file. Each line of the
description must be delimited by double quotes. Although this
description serves the same purposes as the comments starting with
\lstinline$//$, the difference is that it is read by \BBIOGEME\ and
copied verbatim in the report file. Note that this section is optional
and can be omitted.

\begin{lstlisting}[style=nonumbers]
[ModelDescription]
"Example of a logit model for a transportation mode choice"
"with 3 alternatives:"
"- Train"
"- Car"
"- Swissmetro, an hypothetical high-speed train"
\end{lstlisting}

Each parameter to be estimated must be declared in the section
\lstinline$[Beta]$. For each parameter, the following information must be mentioned:
\begin{enumerate}
\item the name of the parameter,
\item the default value,
\item a lower bound,
\item an upper bound,
\item a flag that indicates if the parameter must be estimated (0) or if it keeps its default value (1).
\end{enumerate}
Like for any identifier in \BBIOGEME, the name of the parameter should
comply with the following requirements:  the first character must be a letter
  (any case) or an underscore (\verb+_+), followed by a sequence of
  letters, digits, underscore (\verb+_+) or dashes (\verb+-+), and
  terminated by a white space. Note that case sensitivity is enforced, so that \verb+varname+ and \verb+Varname+ would represent two different variables.
In our example, the default value of each parameter is 0. If a
previous estimation had been performed before, we could have used the
previous estimates as default value. Note that, for the parameters
that are estimated by \BBIOGEME, the default value is used as the
starting value for the optimization algorithm. For the parameters that
are not estimated, the default value is used throughout the estimation
process. In our example, the parameter \lstinline$ASC_SM$ is not
estimated (as specified by the \lstinline$1$ in the fifth position on
the corresponding line), and its value is fixed to \lstinline$0$. 
A lower bound and an upper bound must be specified. By default, we
suggest to use \lstinline$-1000$ and \lstinline$1000$. If the
estimated value of the parameter happens to equal to one of these bounds, it
is a sign that the bounds are too tight and larger value should be
provided. However, most of the time, if a
coefficient reaches the value 1000 or -1000, it means that its
variable is poorly scaled, and that its units should be changed. 
\begin{lstlisting}[style=nonumbers]
[Beta]
// Name Value  LowerBound UpperBound  status (0=variable, 1=fixed)
ASC_CAR 	0 -1000              1000              0
ASC_TRAIN  	0 -1000              1000              0
ASC_SM	        0 -1000              1000              1
B_TIME		0 -1000              1000              0
B_COST		0 -1000              1000              0
\end{lstlisting}

The section \lstinline$[Choice]$ describes to \BBIOGEME\ where the dependent variable (that is, the chosen alternative) can be found in the file. 
\begin{lstlisting}[style=nonumbers]
[Choice]
CHOICE   
\end{lstlisting}
  Note that the syntax is case sensitive, and that \texttt{CHOICE} is
  different from \texttt{choice}, and from \texttt{Choice}. Note also
  that a formula can be specified. In our example, the variable in the
  data file is codes as specified in Table~\ref{tab:choice}.

\begin{table}[htb]
\begin{center}
\begin{tabular}{rl}
Train & 1 \\
Swissmetro & 2 \\
Car & 3
\end{tabular}
\end{center}
\caption{\label{tab:choice}Numbering of the alternatives}
\end{table}

Among other output files, Biogeme generates a file in
\LaTeX\ format. The section \lstinline$LaTeX$ (note the sequence of
upper and lower cases) is used to specify the name of the parameters 
in \LaTeX\ syntax.  This section is optional
and can be omitted.

\begin{lstlisting}[style=nonumbers]
[LaTeX]
ASC_CAR "Cte. car"
ASC_TRAIN "Cte. train"
ASC_SM	"Cte. Swissmetro"
B_TIME	"$\beta_\protect\text{time}$"
B_COST	"$\beta_\protect\text{cost}$"
\end{lstlisting}


The specification of the
utility functions is described in the section \lstinline$[Utilities]$.
 The specification for an alternative
must start at a new row, and may actually span several rows. 
For each alternative, four entries are specified.
\begin{enumerate}
\item The identifier of the alternative: the numbering convention
  must be consistent with the one specified in section
  \lstinline$[Choice]$. In our case, it is the one specified in Table~\ref{tab:choice}.
\item The name of the alternative:  the first character must be a letter
  (any case) or an underscore (\verb+_+), followed by a sequence of
  letters, digits, underscore (\verb+_+) or dashes (\verb+-+), and
  terminated by a white space. The name is case sensitive. 
\item The availability condition. In our example, it is a direct
reference to one of the entries  in the data file. The convention is
that zero is treated as "false", and anything different from zero
(typically, one) is treated as "true".
\item  The linear-in-parameter utility function: it is composed of a list of terms,
         separated by a \texttt{+}. Each term is composed of the name of a
         parameter and the name of an attribute,
         separated by a \texttt{*}. An attribute must be either defined in
         the data file, or in the section \lstinline$[Expressions]$.
         Note that a space is required  after each parameter name.
\end{enumerate}


\begin{lstlisting}[style=nonumbers]
[Utilities]
// Id Name  Avail  linear-in-parameter expression
    1 A1_TRAIN TRAIN_AV_SP ASC_TRAIN * one 
                            + B_TIME * TRAIN_TT_SCALED 
                            + B_COST * TRAIN_COST_SCALED
    2 A2_SM    SM_AV          ASC_SM * one
                            + B_TIME * SM_TT_SCALED
                            + B_COST * SM_COST_SCALED
    3 A3_Car   CAR_AV_SP     ASC_CAR * one 
                            + B_TIME * CAR_TT_SCALED
                            + B_COST * CAR_CO_SCALED
\end{lstlisting}


The section \lstinline$[Expressions]$ describes to \BBIOGEME\ how to
compute attributes not directly available from the data file. 
When boolean expressions are involved, the value TRUE is
  represented by 1, and the value FALSE is represented by
  0. Therefore, a multiplication involving a boolean expression is
  equivalent to a ``AND'' operator. The following code is interpreted in
  the following way:
\begin{itemize}
\item \lstinline$CAR_AV_SP$ is equal to \lstinline$CAR_AV$ is
  \lstinline$SP$ is different from 0, and is equal to 0
  otherwise. \lstinline$TRAIN_AV_SP$ is defined similarly.
\item \lstinline$SM_COST$ is equal to \lstinline$SM_CO$ if
  \lstinline$GA$ is equal to 0, that is, if the traveler does not have
  a yearly pass (called ``general abonment''). If the traveler
  possesses a yearly pass, then \lstinline$GA$ is different from 0,
  and the variable \lstinline$SM_COST$ is zero. The variable
  \lstinline$TRAIN_COST$ is defined in the same way.
\end{itemize}
\begin{lstlisting}[style=nonumbers]
[Expressions]
CAR_AV_SP =  CAR_AV   * (  SP   !=  0  )
TRAIN_AV_SP =  TRAIN_AV   * (  SP   !=  0  )
SM_COST =  SM_CO   * (  GA   ==  0  ) 
TRAIN_COST =  TRAIN_CO   * (  GA   ==  0  )
\end{lstlisting}

Variables can be also be rescaled. For numerical reasons, it is good
practice to scale the data so that the values of the estimated parameters are around 1.0. A previous estimation with the unscaled data has generated
parameters around -0.01 for both cost and time. Therefore, 
time and cost are divided by 100.

\begin{lstlisting}[style=nonumbers]
TRAIN_TT_SCALED = TRAIN_TT / 100
TRAIN_COST_SCALED = TRAIN_COST / 100
SM_TT_SCALED = SM_TT / 100
SM_COST_SCALED = SM_COST / 100
CAR_TT_SCALED = CAR_TT / 100
CAR_CO_SCALED = CAR_CO / 100
\end{lstlisting}

The section \lstinline$[Exclude]$ contains a boolean expression that
is evaluated for each observation in the data file.  Each observation
such that this expression is ``true'' is discarded from the
sample. In our example, the modeler has developed the model only for
work trips, so that every observation such that the trip purpose is not 1
or 3 is removed.
Observations such that the dependent variable \lstinline$CHOICE$ is 0 are also
removed. Remember the convention that ``false'' is represented by 0,
and ``true'' by 1, so that the `*' can be interpreted as a ``and'',
and the `+' as a ``or''. The exclude condition in our example is
therefore interpreted as: either (\lstinline$PURPOSE$ different from 1
and \lstinline$PURPOSE$ different from 3), or \lstinline$CHOICE$ equal
to 0. 

\begin{lstlisting}[style=nonumbers]
[Exclude]
(( PURPOSE != 1 ) * (  PURPOSE   !=  3  ) + ( CHOICE == 0 )) 
\end{lstlisting}

Finally, the section \lstinline$[Model]$ specifies the model to be
estimated. This basically tells \BBIOGEME\  which assumptions must
be used regarding the error term. In this example, it is the logit
model (or MNL, for \emph{multinomial logit}, as it is sometimes
called), characterized by the keyword \lstinline&$MNL&.


\begin{lstlisting}[style=nonumbers]
[Model]
// $MNL stands for MultiNomial Logit 
$MNL
\end{lstlisting}


\section{Running \BBIOGEME}

The estimation of the model is performed using the following command 
\begin{lstlisting}
biogeme 01logit swissmetro.dat
\end{lstlisting}

The following information is displayed during the execution.
\begin{itemize}
\item Some information about the version of Biogeme.

\begin{lstlisting}[basicstyle=\ttfamily\tiny]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
biogeme 2.4 [Dim 9 aoû 2015 18:28:59 EDT]
Michel Bierlaire, EPFL
-- Compiled by michelbierlaire on Darwin
See http://biogeme.epfl.ch
                    !! CFSQP is available !!
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	"In every non-trivial program there is at least one bug."
\end{lstlisting}
\item Some information about the \lstinline$.par$ file, that can be
  used to customize the execution of \BBIOGEME. This file is not mandatory. If it does not exist, \BBIOGEME\ uses the default values, and automatically creates a file named \lstinline+default.par+.
If entries are missing in the file, \BBIOGEME\ uses the default values.
Note that \BBIOGEME\ first looks for a file called
\lstinline$01logit.par$, that would be specific for this 
model. If it does not exist, it is looking for the file
\lstinline+default.par+. As it does not exist either, it is created
and populated with default values of the most useful parameters. It
can be edited later on. 
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
[17:03:51]patFileNames.cc:52  01logit.par does not exist
[17:03:51]patFileNames.cc:56  Trying default.par instead
[17:03:51]patBiogeme.cc:138  File default.par does not exist. Default values will be used
[17:03:51]patBiogeme.cc:140  A file default.par has been created
\end{lstlisting}
Note that each line above is associated with a time, the name of a file
containing the source code and a line number. This
information is designed for debugging purposes and can be ignored by
most users. 
\item The data file is then read. As some data files may be long, the
  progress of the reading is reported every 500 rows, together with
  the memory usage. 
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
 Opening file swissmetro.dat
 Data  file... line 500	Memory: 167 Kb
 Data  file... line 1000	Memory: 317 Kb
 Data  file... line 1500	Memory: 317 Kb
...
 Data  file... line 10500	Memory: 2 Mb
 Total obs.:   10727
 Total memory: 2273.62 Kb
 Run time for data processing: 00:01
\end{lstlisting}
\item The details about the iterations of the estimation procedure are
  reported. 
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
 Init loglike=-6964.66
     gmax Iter   radius        f(x)     Status       rhok nFree
 +1.44e-01    1 1.00e+00 +6.9646630e+03 ****Converg  +1.07e+00 4  ++ P
 +4.12e-02    2 2.00e+00 +5.4217993e+03 ****Converg  +1.08e+00 4  ++ P
 +7.22e-03    3 4.00e+00 +5.3328087e+03 ****Converg  +1.02e+00 4  ++ P
 +1.79e-04    4 8.00e+00 +5.3312529e+03 ****Converg  +1.00e+00 4  ++ P

 Convergence reached...
--> time interval [17:03:52,17:03:52]
 Run time: 00:00
 Final log-likelihood=-5331.25
\end{lstlisting}
\item \BBIOGEME\ prepares the output, and provides the list of files
  that have been involved in this run.
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
 Be patient... BIOGEME is preparing the output files
--> time interval [17:03:52,17:03:52]
 Run time for var/covar computation: 00:00
 BIOGEME Input files
 ===================
 Parameters:			default.par
 Model specification:		01logit.mod
 Sample 1 :				swissmetro.dat
 BIOGEME Output files
 ====================
 Estimation results:		01logit.rep
 Estimation results (HTML):	01logit.html
 Estimation results (Latex):	01logit.tex
 Estimation results (ALogit):	01logit.F12
 Result model spec. file:	01logit.res
 Sample statistics:		01logit.sta
 BIOGEME Debug files
 ===================
 Log file:			01logit.log
 Parameters debug:		parameters.out
 Model debug:			model.debug
 Model spec. file debug:		__specFile.debug
 Model informations: Logit Model
 ==================
 The minimum argument of exp was -18.353

 Run time for estimation:      00:00
 Total run time:               00:01
\end{lstlisting}
\end{itemize}

The following files are generated by \BBIOGEME:
\begin{itemize}
\item \lstinline$01logit.F12$: a file containing the main results in ALogit format.
\item \lstinline$01logit.html$: the results of the estimation in Html
  format. Its content is identical to the content of the file
  \lstinline$01logit.rep$, and is described in Section~\ref{sec:bisonreport}.
\item \lstinline$01logit.log$: a file containing messages produced by \BBIOGEME\ during the run.
\item \lstinline$01logit.rep$: the results of the estimation in text
  format. Its content is described in Section~\ref{sec:bisonreport}.
\item \lstinline$01logit.res$: a file containing the specification of
  the estimated model, in the same format as the model specification
  file. The default value for each estimated parameter has been
  replaced by its estimate. 
\item \lstinline$01logit.sta$:  a file containing some descriptive statistics on the data.
\item \lstinline$01logit.tex$: a file containing the main results in
  \LaTeX\ format. See Table~\ref{tab:latex}.
\item \lstinline$__specFile.debug$: after \BBIOGEME\ has read the
  model specification file, it reports what has been understood in the
  file \lstinline$__specFile.debug$. It is useful to debug the
  specification, as it allows to identify what has been misunderstood
  by \BBIOGEME.
\item \lstinline$default.par$: default \lstinline$.par$ file
  customizing \BBIOGEME, containing the most used parameters. See Table~\ref{tab:par}.
\item \lstinline$hess.lis$: contains the final BHHH and the second
  derivative, or Hessian, matrix. The format is such that it can be
  copied and pasted in a matrix language such as Matlab or Octave. 
\item \lstinline$hessian.lis$: contains the (opposite of the) Hessian
  matrix of the log likelihood function at each iteration, in a Matlab
  compatible format. 
\item \lstinline$model.debug$: reports the internal representation of
  the model, for debugging purposes. 
\item \lstinline$parameters.out$: provides an exhaustive list of the
  parameters used by the run of \BBIOGEME, together with the value
  that has been used. 
\item \lstinline$summary.html$: this file is designed to consolidate
  the results of several runs of \BBIOGEME, with several different
  models, into one summary report. It will be updated each time
  \BBIOGEME\ is run in the same directory. 
\end{itemize}

\begin{table}[htb]
\footnotesize
\begin{flushleft}
\begin{tabular}{rcl}
\hline
Model &:& Logit\\
Number of estimated parameters&:&4\\
Number of  observations &:& 6768\\
Number of individuals&:&6768\\
Null log-likelihood&:&-6964.663\\
Init log-likelihood&:&-6964.663\\
Final log-likelihood&:&-5331.252\\
Likelihood ratio test &:&3266.822\\
Rho-square&:&0.235\\
Adjusted rho-square&:&0.234\\
Final gradient norm&:&+6.288e-04\\
Diagnostic&:&Convergence reached...\\
Iterations&:&4\\
Run time&:&00:00\\
Variance-covariance&:&from analytical hessian
\\
Sample file&:&swissmetro.dat\\
\end{tabular}
\end{flushleft}
%%
%%
%%
  \begin{tabular}{l}
\begin{tabular}{rlr@{.}lr@{.}lr@{.}lr@{.}l}
         &                       &   \multicolumn{2}{l}{}    & \multicolumn{2}{l}{Robust}  &     \multicolumn{4}{l}{}   \\
Parameter &                       &   \multicolumn{2}{l}{Coeff.}      & \multicolumn{2}{l}{Asympt.}  &     \multicolumn{4}{l}{}   \\
number &  Description                     &   \multicolumn{2}{l}{estimate}      & \multicolumn{2}{l}{std. error}  &   \multicolumn{2}{l}{$t$-stat}  &   \multicolumn{2}{l}{$p$-value}   \\

\hline

1 & Cte. car & -0&155 & 0&0582 & -2&66 & 0&01 \\
2 & Cte. train & -0&701 & 0&0826 & -8&49 & 0&00 \\
3 & $\beta_\protect\text{cost}$ & -1&08 & 0&0682 & -15&89 & 0&00 \\
4 & $\beta_\protect\text{time}$ & -1&28 & 0&104 & -12&26 & 0&00 \\
\hline
\end{tabular}
\\
\begin{tabular}{rcl}
\multicolumn{3}{l}{\bf Summary statistics}\\
\multicolumn{3}{l}{ Number of observations = $6768$} \\
 $\mathcal{L}(0)$ &=&  $-6964.663$ \\
 $\mathcal{L}(c)$ &=& ???\\
 $\mathcal{L}(\hat{\beta})$ &=& $-5331.252 $  \\
 $-2[\mathcal{L}(0) -\mathcal{L}(\hat{\beta})]$ &=& $3266.822$ \\
    $\rho^2$ &=&   $0.235$ \\
    $\bar{\rho}^2$ &=&    $0.234$ \\
\end{tabular}
\end{tabular}
\caption{\label{tab:latex}Results of the estimation in \LaTeX}
\end{table}

\begin{table}[htb]
\begin{lstlisting}[style=nonumbers]
[GEV]
gevAlgo = "BIO"
gevScreenPrintLevel = 1
gevLogFilePrintLevel = 2
gevRandomDistrib = "MLHS"
gevPrintVarCovarAsList = 1
gevPrintVarCovarAsMatrix = 0
gevPrintPValue  = 1
gevDecimalDigitsStats = 3
gevSignificantDigitsParameters = 3
gevDecimalDigitsTTest  = 2
gevNumberOfThreads  = 2

[BasicTrustRegion]
BTRMaxIter = 1000

[cfsqp]
cfsqpMaxIter = 1000

[solvopt]
solvoptMaxIter = 1000
\end{lstlisting}
\caption{\label{tab:par}The \lstinline$.par$ file generated by default}
\end{table}

\clearpage
\section{\BBIOGEME: the report file}
\label{sec:bisonreport}

The report file generated by \BBIOGEME\ gathers various information
about the result of the estimation. First, some information about the
version of Biogeme, and any description included in the
\lstinline$ModelDescription$ section. 


\begin{lstlisting}[style=tiny]
// This file has automatically been generated.
// Tue Aug 11 17:03:52 2015
// Michel Bierlaire, EPFL

biogeme 2.4 [Dim 9 aoû 2015 18:28:59 EDT]
Michel Bierlaire, EPFL

   Example of a logit model for a transportation mode choice
   with 3 alternatives:
   - Train
   - Car
   - Swissmetro, an hypothetical high-speed train
\end{lstlisting}

Next, a series of generic information about the estimation are provided. 
   \begin{itemize}
      \item The type of the model that has been estimated.
      \item The number of parameters that have been estimated.
      \item The number of observations, that is, the number of rows in
        the data file  that have not been excluded.
      \item The number of individuals in the sample. It is different
        from the number of observations in the case of
        panel data, where several observations may be associated with the
        same individual. 
      \item The \lstinline+Null log likelihood+ is the log likelihood
        of the sample for a logit model such that the deterministic
        part of the utility function is zero for all alternatives,
        that is
         \begin{equation}
            \label{eq:l0}
            \mathcal{L}^0 = \sum_{n \in \protect\text{sample}} \omega_n \ln \frac{1}{\# \mathcal{C}_n}
         \end{equation}
         where $\# \mathcal{C}_n$ is the number of alternatives available to
         individual $n$ and $\omega_n$ is the associated weight.
      \item \lstinline+Cte log likelihood+ is the log likelihood of the
sample for a logit model where the  deterministic
        part of the utility function of each alternative contains only 
the alternative specific constant. \textbf{If all alternatives are
always available},  it is computed as
\begin{equation}
\label{eq:ctelike}
\sum_{j \in \C} n_j \ln n_j - n \ln n,
\end{equation}
where $n_j$ is the number of times alternative $j$ has been chosen,
and $n=\sum_{j \in \C} n_j$ is the number of observations in the
sample. Note that if some alternatives are not available for some
observations, the formula \req{eq:ctelike} is not valid, and the value is not reported. 
      \item \lstinline+Init log likelihood+ is the log likelihood of
        the sample for the model defined with the default values of
        the parameters provided in the \lstinline+.mod+ file. 
      \item \lstinline+Final log likelihood+ is the log likelihood of the sample for the estimated model. 
      \item \lstinline+Likelihood ratio test+ is 
         \begin{equation}
            -2 ( \mathcal{L}^0 - \mathcal{L}^*)
         \end{equation}
         where 
         $ \mathcal{L}^0$ is the null log likelihood as defined above, and $\mathcal{L}^*$ is the log likelihood of the sample for the estimated model. 
      \item \lstinline+Rho-square+ is
         \begin{equation}
            \rho^2 = 1 - \frac{\mathcal{L}^*}{\mathcal{L}^0}.
         \end{equation}
        \item \lstinline+Adjusted rho-square+ is
         \begin{equation}
            \rho^2 = 1 - \frac{\mathcal{L}^* - K}{\mathcal{L}^0}.
         \end{equation}
         where $K$ is the number of estimated parameters. Note that this statistic is meaningless in the presence of constraints, where the number of degrees of freedom is less than  the number of parameters. 
      \item \lstinline+Final gradient norm+ is the gradient of the log
        likelihood function computed for the estimated parameters. If
        no constraint is active at the solution, it should be close to
        0. If there are equality constraints, or if some bound
        constraints or inequality constraints are active at the
        solution (that is, they are verified with equality), the
        gradient may not be close to zero.
\item \lstinline+Diagnostic+ is the diagnostic reported by the optimization
algorithm. If the algorithm has not converged, the estimation results presented
in the file cannot be used as such. 
\item \lstinline+Iterations+ is the number of iterations used by the
algorithm before it stopped. 
\item \lstinline+Run time+ is the actual time used by the algorithm before
it stopped, in minutes and seconds (format \texttt{mm:ss}).
   \item \lstinline+Variance-covariance+ specifies how the second-derivative matrix (inverted to obtain the variance-covariance matrix) has been calculated. It can be either from a finite difference approximation  (which is accurate, but may take time to compute), or from the BHHH matrix (which is less accurate, but faster to compute, see
         \cite{BernHallHallHaus74}). The user selects this option with
         parameter \texttt{gevVarCovarFromBHHH}.
\item \lstinline+Sample file+: the name of the file containing the data.
   \end{itemize}



\begin{lstlisting}[style=tiny]
                         Model: Logit
Number of estimated parameters: 4
        Number of observations: 6768
         Number of individuals: 6768
           Null log likelihood: -6964.663
           Init log likelihood: -6964.663
          Final log likelihood: -5331.252
         Likelihood ratio test: 3266.822
                    Rho-square: 0.235
           Adjusted rho-square: 0.234
           Final gradient norm: +6.288e-04
                    Diagnostic: Convergence reached...
                    Iterations: 4
                      Run time: 00:00
           Variance-covariance: from analytical hessian
                   Sample file: swissmetro.dat
\end{lstlisting}

The following section reports the estimates of the parameters of the
utility function,
together with some statistics. For each parameter $\beta_k$, the following is reported:
   \begin{itemize}
  \item The name of the parameter.
      \item The estimated value $\beta_k$. 
      \item The standard error $\sigma_k$ of the estimate, calculated as the
         square root of the $k$\th diagonal entry of the
         Rao-Cramer bound (see Appendix~\ref{sec:robust}).
     \item The $t$ statistics, calculated as $t_k=\beta_k/\sigma_k$.
     \item The $p$ value, calculated as $2 (1 - \Phi(t_k))$,
where $\Phi(\cdot)$ is the cumulative density function of the
univariate standard normal distribution. 
     \item  A sign \lstinline$*$ is
         appended if the absolute value value of $t_k$ is less than
         1.96, emphasizing a potential lack of statistical
         significance. In this example, no such sign appears. 
      \item The robust standard error $\sigma^R_k$ of the estimate, calculated as the
         square root of the $k$\th diagonal entry of the
         robust estimate of the variance covariance matrix. (see Appendix~\ref{sec:robust}).
     \item The robust $t$ statistics, calculated as $t^R_k=\beta_k/\sigma^R_k$.
     \item The robust $p$ value, calculated as $2 (1 - \Phi(t^R_k))$,
where $\Phi(\cdot)$ is the cumulative density function of the
univariate normal distribution. 
     \item  A sign \lstinline$*$ is
         appended if the absolute value value of $t^R_k$ is less than
         1.96, emphasizing a potential lack of statistical
         significance. In this example, no such sign appears. 
   \end{itemize}


\begin{lstlisting}[style=tiny]
Utility parameters
******************
Name      Value  Std err   t-test p-val Rob. std err Rob. t-test Rob. p-val 
----      -----  -------   ------ ----- ------------ ----------- ---------- 
ASC_CAR   -0.155 0.0432    -3.58  0.00  0.0582       -2.66       0.01       
ASC_SM    0.00   --fixed--                                                  
ASC_TRAIN -0.701 0.0549    -12.78 0.00  0.0826       -8.49       0.00       
B_COST    -1.08  0.0518    -20.91 0.00  0.0682       -15.89      0.00       
B_TIME    -1.28  0.0569    -22.46 0.00  0.104        -12.26      0.00       
\end{lstlisting}

The following section  reports, for each alternative, its identifier, its name, its availability condition, and the specification of its utility
function.

\begin{lstlisting}[style=tiny]
Utility functions
*****************
1 A1_TRAIN TRAIN_AV_SP ASC_TRAIN * one + B_TIME * TRAIN_TT_SCALED + B_COST * TRAIN_COST_SCALED
2 A2_SM	SM_AV ASC_SM * one + B_TIME * SM_TT_SCALED + B_COST * SM_COST_SCALED
3 A3_Car CAR_AV_SP ASC_CAR * one + B_TIME * CAR_TT_SCALED + B_COST * CAR_CO_SCALED
\end{lstlisting}

The following section reports, for each pair of parameters $k$ and
$\ell$,
\begin{itemize}
\item the name of $\beta_k$,
\item the name of $\beta_\ell$,
\item the entry $\Sigma_{k,\ell}$ of the 
         Rao-Cramer bound (see Appendix~\ref{sec:robust}),
\item the correlation between $\beta_k$ and $\beta_\ell$, calculated as
\begin{equation}
\frac{\Sigma_{k,\ell}}{\sqrt{\Sigma_{k,k}\Sigma_{\ell,\ell}}},
\end{equation}
\item the $t$ statistics, calculated as
\begin{equation}
t_{k,\ell}= \frac{\beta_k - \beta_\ell}{\sqrt{\Sigma_{k,k} + \Sigma_{\ell,\ell} - 2 \Sigma_{k,\ell}}},
\end{equation}
  \item  a sign \lstinline$*$ is
         appended if the absolute value value of $t_{k,\ell}$ is less than
         1.96, emphasizing that the hypothesis that the two parameters
         are equal cannot be rejected at the 5\% level (in this example, no such sign appears), 
\item the entry $\Sigma^R_{k,\ell}$ of $\Sigma^R$, the robust estimate of the variance covariance matrix (see Appendix~\ref{sec:robust}),
\item the robust correlation between $\beta_k$ and $\beta_\ell$, calculated as
\begin{equation}
\frac{\Sigma^R_{k,\ell}}{\sqrt{\Sigma^R_{k,k}\Sigma^R_{\ell,\ell}}},
\end{equation}
\item the robust $t$ statistics, calculated as
\begin{equation}
t^R_{k,\ell}=\frac{\beta_k - \beta_\ell}{\sqrt{\Sigma^R_{k,k} + \Sigma^R_{\ell,\ell}
    - 2 \Sigma^R_{k,\ell}}},
\end{equation}
  \item  a sign \lstinline$*$ is
         appended if the absolute value value of $t^R_{k,\ell}$ is less than
         1.96, emphasizing that the hypothesis that the two parameters
         are equal cannot be rejected at the 5\% level (in this
         example, one such sign appears, for parameters
         \lstinline$B_COST$ and \lstinline$B_TIME$). 
\end{itemize}
The final line reports the value of the smallest singular value of the
second derivatives matrix. A value close to zero is a sign of
singularity, that may be due to a lack of variation in the data or
an unidentified model.

\begin{lstlisting}[style=tiny]
Correlation of coefficients
***************************
Coeff1    Coeff2    Covariance Correlation t-test Rob. covar. Rob. correl. Rob. t-test   
------    ------    ---------- ----------- ------ ----------- ------------ -----------   
B_COST    B_TIME    0.000550   0.187       2.79   0.00220     0.309        1.84        * 
ASC_TRAIN B_TIME    -0.00225   -0.722      5.56   -0.00760    -0.883       3.18          
ASC_TRAIN B_COST    8.22e-06   0.00289     5.08   -0.000831   -0.147       3.34          
ASC_CAR   B_TIME    -0.00144   -0.585      12.57  -0.00482    -0.796       7.27          
ASC_CAR   B_COST    0.000485   0.216       15.52  2.86e-05    0.00722      10.40         
ASC_CAR   ASC_TRAIN 0.00138    0.580       11.85  0.00390     0.812        11.16         

Smallest singular value of the hessian: 63.2021
\end{lstlisting}

\clearpage 


\appendix

\section{Complete specification file}

\subsection{\lstinline$01logit.mod$}
\label{sec:modelBison}
\lstinputlisting[style=numbers,basicstyle=\footnotesize]{../../../test/swissmetro_bison/01logit.mod}

\clearpage

   \section{Estimation of the  variance-covariance matrix}
   \label{sec:robust}
Under relatively general conditions,  the asymptotic
variance-covariance matrix of the maximum likelihood
estimates of the vector of parameters $\theta \in \R^K$ is given by the Cramer-Rao bound
\begin{equation}
  \label{eq:RaoCramer}
  -\expect\left[ \nabla^2 \L(\theta)\right]^{-1} =  \left\{-\expect\left[\frac{\partial^2 \L(\theta)}{\partial \theta \partial \theta^T}\right]\right\}^{-1}.
\end{equation}
The term in square brackets is the matrix of the second derivatives
of the log likelihood function with respect to the parameters
evaluated at the true parameters.  Thus the entry in the $k$\/th row and
the $\ell$\/th column is
\begin{equation}
  \label{eq:BAL4.34}
 \frac{\partial^2 \L(\theta)}{\partial \theta_k \partial \theta_{\ell}}.
\end{equation}

Since we do not know the actual values of the parameters at which to
evaluate the second derivatives, or the distribution of $x_{in}$ and
$x_{jn}$ over which to take their expected value, we estimate the
variance-covariance matrix by evaluating the second derivatives  at the estimated parameters
$\hat{\theta}$ and the sample distribution of $x_{in}$ and $x_{jn}$ instead of
 their true distribution. Thus we use
\begin{equation}
  \label{eq:BAL4.35}
  \expect\left[\frac{\partial^2 \L(\theta)}{\partial \theta_k \partial \theta_\ell}  \right]\approx \sum_{n=1}^N \left[\frac{\partial^2\left(y_{in}\ln P_n(i) + y_{jn} \ln P_n(j) \right)}{\partial \theta_k \partial \theta_\ell} \right]_{\theta=\hat{\theta}},
\end{equation}
as a consistent estimator of the matrix of second derivatives. 

Denote
this matrix as $\hat{A}$. Note that, from the second order optimality conditions of the optimization
problem, this matrix is negative semi-definite, which is the algebraic equivalent of the local  concavity of the
log likelihood function.
 If the maximum is unique, the matrix is negative definite, and the
 function is locally strictly concave. 




 An estimate of the Cramer-Rao
bound \req{eq:RaoCramer} is given by 
\begin{equation}
\label{eq:EstimateRaoCramer}
\widehat{\Sigma}^{\protect\text{CR}}_{\theta} = -\hat{A}^{-1}.
\end{equation}
If  the matrix $\hat{A}$ is  negative definite then $-\hat{A}$ is invertible and the Cramer-Rao bound is positive definite. 

Another consistent estimator of the (negative of the) second
derivatives matrix can be obtained by the matrix of the cross-products of first derivatives as follows:
\begin{equation}
\label{eq:binaryBHHH}
-E\left[ \frac{\partial^2 \L(\theta)}{\partial \theta \partial \theta^T}\right] \approx  \sum_{n=1}^n \left(\frac{\partial \ell_n(\hat{\theta})}{\partial \theta} \right)\left(\frac{\partial \ell_n(\hat{\theta})}{\partial \theta} \right)^T = \hat{B},
\end{equation}
 where
\begin{equation}
\left(\frac{\partial \ell_n(\hat{\theta})}{\partial \theta} \right) = \frac{\partial}{\partial \theta} (\log P(i_n|\C_n;\widehat{\theta}))
\end{equation}
is the gradient vector of the likelihood of observation $n$.
This approximation is employed by the BHHH algorithm, from the work by \citeasnoun{BernHallHallHaus74}. Therefore, an estimate of the variance-covariance matrix 
is given by 
\begin{equation}
\widehat{\Sigma}^{\protect\text{BHHH}}_{\theta} =\hat{B}^{-1},
\end{equation}
 although it is rarely used. 
Instead, $\hat{B}$ is
used to derive  a third consistent estimator of the variance-covariance matrix of
the parameters, defined as
\begin{equation}
\label{eq:robustEstimator}
\widehat{\Sigma}^{\protect\text{R}}_{\theta} = (-\hat{A})^{-1} \; \widehat{B}\; (-\hat{A})^{-1} = \widehat{\Sigma}^{\protect\text{CR}}_{\theta} \; (\widehat{\Sigma}^{\protect\text{BHHH}}_{\theta})^{-1} \; \widehat{\Sigma}^{\protect\text{CR}}_{\theta}.
\end{equation}

It is
called the \emph{robust} estimator, or sometimes the \emph{sandwich}
estimator, due to the form of equation
\req{eq:robustEstimator}. \BIOGEME\ reports statistics based on  both the Cramer-Rao estimate
\req{eq:EstimateRaoCramer} and the robust estimate \req{eq:robustEstimator}.


 When the true likelihood function is maximized,  these estimators are
 asymptotically equivalent, and the Cramer-Rao bound should be
preferred (\cite{KaueCarr2001}).  When other consistent estimators are
used, the robust estimator must be used
(\cite{Whit82}). Consistent non-maximum likelihood estimators, known
as pseudo maximum likelihood estimators, are often used when the true
likelihood function is unknown or difficult to compute. In such cases,
it is often possible to obtain consistent estimators by maximizing an
objective function based on a simplified probability distribution. 

\bibliographystyle{dcu}
\bibliography{../dca}





\end{document}





